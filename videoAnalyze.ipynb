{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "videoAnalyze.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvqmsm7jVIGmQWXV1Q64Vy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hysakada/IA-FER/blob/master/videoAnalyze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NKnUf3ug17w"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing import image\n",
        "import time\n",
        "\n",
        "timer_a = time.time()\n",
        "timer_b = time.time()\n",
        "\n",
        "#load model\n",
        "model = model_from_json(open(\"fer.json\", \"r\").read())\n",
        "#load weights\n",
        "model.load_weights('fer.h5')\n",
        "\n",
        "\n",
        "emotionsCount =[0,0,0,0,0,0,0]\n",
        "emotions=(\"Felicidade\", \"Surpresa\", \"Nojo\",\"Raiva\",\"Medo\",\"Tristeza\",\"Neutro\")\n",
        "emotionsResult=[0,0,0,0,0,0,0]\n",
        "maior=0 ; index=0\n",
        "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "\n",
        "cap=cv2.VideoCapture('http://192.168.1.5:4747/video') #IP do APP Droidcam do celular\n",
        "\n",
        "while time.time() - timer_b < 60: #60= segundos que vai ficar ligado\n",
        "    ret,test_img=cap.read()# captures frame and returns boolean value and captured image\n",
        "    if not ret:\n",
        "        continue\n",
        "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
        "\n",
        "    \n",
        "    for (x,y,w,h) in faces_detected:\n",
        "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
        "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
        "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
        "        img_pixels = image.img_to_array(roi_gray)\n",
        "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
        "        img_pixels /= 255\n",
        "\n",
        "        predictions = model.predict(img_pixels)\n",
        "\n",
        "        #find max indexed array\n",
        "        result = np.argmax(predictions[0])#guardando o resultado da emoção (numerico)\n",
        "        emotionsCount[result]=emotionsCount[result]+1#guardando a quantidade de vezes que a emoção foi captada\n",
        "\n",
        "        for ind in range(7): #verificando qual foi a emoção que mais foi capturada\n",
        "          if emotionsCount[ind] > maior:\n",
        "             maior=emotionsCount[ind]\n",
        "             index=ind \n",
        "\n",
        "        if time.time() - timer_a > 2: #após 2 segundos vou pegar a emoção que mais foi capturada e fazer ela ser contabilizada \n",
        "           timer_a=time.time()\n",
        "           emotionsResult[result] = emotions[max_resultindex]\n",
        "           total=total+1\n",
        "           emotionsCount=[0,0,0,0,0,0,0]\n",
        "           maior=0\n",
        "\n",
        "        \n",
        "\n",
        "        cv2.putText(test_img, emotions[result], (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "\n",
        "    resized_img = cv2.resize(test_img, (1000, 700))\n",
        "    cv2.imshow('Facial emotion analysis ',resized_img)\n",
        "\n",
        "\n",
        "\n",
        "    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rrcclui7jTnw"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib\n",
        "from pylab import title, figure, xlabel, ylabel, xticks, bar, legend, axis, savefig\n",
        "from fpdf import FPDF\n",
        "\n",
        "\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['Emoções'] = [\"Felicidade\", \"Surpresa\", \"Nojo\",\"Raiva\",\"Medo\",\"Tristeza\",\"Neutro\"]\n",
        "df['Paciente'] = [emotionsResult[0],emotionsResult[1],emotionsResult[2],emotionsResult[3],emotionsResult[4],emotionsResult[5],emotionsResult[6]]\n",
        "\n",
        "\n",
        "title(\"Amostragem de emoções\")\n",
        "xlabel('Emoção')\n",
        "ylabel('Quantidade')\n",
        "\n",
        "c = [2.0, 4.3, 6.3, 8.0,10.0,12.0,14.0]\n",
        "m = [x - 0 for x in c]\n",
        "\n",
        "xticks(c, df['Emoções'])\n",
        "\n",
        "bar(m, df['Paciente'], width=0.5, color=\"skyblue\", label=\"Paciente\")\n",
        "\n",
        "\n",
        "legend()\n",
        "axis([1, 15, 0, 20]) #configuração do grafico\n",
        "savefig('barchart.png')\n",
        "\n",
        "\n",
        "\n",
        "pdf = FPDF()\n",
        "pdf.add_page()\n",
        "\n",
        "pdf.image('barchart.png', x = 0, y = 0, w = 200, h =150, type = '', link = '')\n",
        "pdf.image('feliz.jpg', x = 10, y = 160, w = 10, h = 10, type = '', link = '')  \n",
        "pdf.image('surpresa.png', x = 10, y = 180, w = 10, h = 10, type = '', link = '')\n",
        "pdf.image('nojo.png', x = 10, y = 200, w = 10, h = 10, type = '', link = '')\n",
        "pdf.image('raiva.jpeg', x = 10, y = 220, w = 10, h = 10, type = '', link = '')\n",
        "pdf.image('medo.jpeg', x = 10, y = 240, w = 10, h = 10, type = '', link = '')\n",
        "pdf.image('triste.png', x = 10, y = 260, w = 10, h = 10, type = '', link = '')\n",
        "pdf.image('neutro.png', x = 10, y = 280, w = 10, h = 10, type = '', link = '')\n",
        "\n",
        "\n",
        "#aqui em baixo está calculando a porcentagem de cada emoção e transformando em string\n",
        "feliz=str(round((emotionsResult[0]/total)*100))\n",
        "surpresa=str(round((emotionsResult[1]/total)*100))\n",
        "nojo=str(round((emotionsResult[2]/total)*100))\n",
        "raiva=str(round((emotionsResult[3]/total)*100))\n",
        "medo=str(round((emotionsResult[4]/total)*100))\n",
        "triste=str(round((emotionsResult[5]/total)*100))\n",
        "neutro=str(round((emotionsResult[6]/total)*100))\n",
        "\n",
        "pdf.set_font('arial', 'B', 12)\n",
        "#pdf.cell(50, 300, \"Tabela\", 0, 0, 'l')\n",
        "pdf.text(22,166,feliz) #feliz\n",
        "pdf.text(22,186,surpresa) #surpresa\n",
        "pdf.text(22,206,nojo) #nojo\n",
        "pdf.text(22,226,raiva) #raiva\n",
        "pdf.text(22,246,medo) #medo\n",
        "pdf.text(22,266,triste) #triste\n",
        "pdf.text(22,286,neutro) #neutro\n",
        "\n",
        "pdf.output('EmotionReport.pdf', 'F')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}